{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P4 Backward propogation\n",
    "Voor deze opdracht moeten we een neural network maken met backward propogation. Hieronder Importeer ik alle bestanden waar dit in gedaan wordt en test ik vervolgens de AND en XOR gate en de Half Adder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from P4.code.neuron import Neuron\n",
    "from P4.code.neuronlayer import NeuronLayer\n",
    "from P4.code.neuronnetwerk import NeuronNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan de gates testen door middel van de voorbeelden in het werkboek van les 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AND Gate\n",
    "\n",
    "De AND Gate zag er als volgt uit:\n",
    "<img src=\"./images/and.png\" alt=\"image\" width=\"400\"/>\n",
    "\n",
    "De values waren als volgt:\n",
    "\n",
    "<img src=\"./images/and_values.png\" alt=\"image\" width=\"300\"/>\n",
    "\n",
    "Met deze info zagen de iteraties er als volgt uit (we doen maar 1 epoch dus we hebben 4 iteraties):\n",
    "\n",
    "<img src=\"./images/and_it1.png\" alt=\"image\" width=\"500\"/>\n",
    "<img src=\"./images/and_it2.png\" alt=\"image\" width=\"500\"/>\n",
    "<img src=\"./images/and_it3.png\" alt=\"image\" width=\"500\"/>\n",
    "<img src=\"./images/and_it4.png\" alt=\"image\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder maken we de neuron aan en tonen we wat wij krijgen uit onze AND gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: returns [0.818] with an input of [0, 0] and a loss of 0.251\n",
      "VALUES AFTER UPDATE: weights: [-0.5, 0.5], error: 0.122, bias: 1.378\n",
      "\n",
      "Epoch 1: returns [0.706] with an input of [1, 0] and a loss of 0.241\n",
      "VALUES AFTER UPDATE: weights: [-0.647, 0.5], error: 0.147, bias: 1.232\n",
      "\n",
      "Epoch 1: returns [0.85] with an input of [0, 1] and a loss of 0.225\n",
      "VALUES AFTER UPDATE: weights: [-0.647, 0.391], error: 0.109, bias: 1.123\n",
      "\n",
      "Epoch 1: returns [0.704] with an input of [1, 1] and a loss of 0.214\n",
      "VALUES AFTER UPDATE: weights: [-0.585, 0.453], error: -0.062, bias: 1.185\n"
     ]
    }
   ],
   "source": [
    "n1 = Neuron([-0.5, 0.5], 1.5)\n",
    "l1 = NeuronLayer([n1])\n",
    "network = NeuronNetwork([l1], 1)\n",
    "\n",
    "network.train([[0,0],[1,0],[0,1],[1,1]],[0,0,0,1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je ziet klopt alles. Het enige wat niet hetzelfde is is de loss, maar dit is een fout in het werkboek (als het goed is). Want aan het begin wordt getoond dat de loss bij [0,0] 0.251 is, maar bij de eerste iteratie staat er opeens dat het 0.241 is.\n",
    "\n",
    "<img src=\"./images/and_correct.png\" alt=\"image\" width=\"500\"/>\n",
    "\n",
    "Ik heb zelf met de hand ook gerekend en kwam op hetzelfde antwoord uit als hier. Mijn code kwam ook hierop. Dus ik denk dat alles eentje omlaag moet. [0,0] heeft een loss van 0.251, [1,0] heeft een loss van 0.241 ipv 0.225, [0,1] heeft 0.225 ipv 0.214. enz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR Gate\n",
    "\n",
    "De XOR Gate zag er als volgt uit:\n",
    "<img src=\"./images/xor.png\" alt=\"image\" width=\"400\"/>\n",
    "\n",
    "De values waren als volgt:\n",
    "\n",
    "<img src=\"./images/xor_values.png\" alt=\"image\" width=\"300\"/>\n",
    "\n",
    "Met deze info zagen de iteraties er als volgt uit (we doen maar 1 epoch, maar in het werkboek worden alleen de eerste 2 iteraties getoond):\n",
    "\n",
    "<img src=\"./images/xor_it1.png\" alt=\"image\" width=\"500\"/>\n",
    "<img src=\"./images/xor_it2.png\" alt=\"image\" width=\"500\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder de xor gate. We gaan alle inputs en targets meegeven, maar om te vergelijken moet je naar de eerste 2 kijken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: returns [0.709] with an input of [1, 1] and a loss of 0.144\n",
      "VALUES AFTER UPDATE: weights: [0.186, -0.414], error: 0.014, bias: -0.014\n",
      "VALUES AFTER UPDATE: weights: [0.68, 0.08], error: 0.02, bias: -0.02\n",
      "VALUES AFTER UPDATE: weights: [0.534, 0.799], error: 0.146, bias: -0.146\n",
      "\n",
      "Epoch 1: returns [0.617] with an input of [0, 1] and a loss of 0.135\n",
      "VALUES AFTER UPDATE: weights: [0.186, -0.428], error: 0.014, bias: -0.028\n",
      "VALUES AFTER UPDATE: weights: [0.68, 0.056], error: 0.023, bias: -0.044\n",
      "VALUES AFTER UPDATE: weights: [0.57, 0.846], error: -0.091, bias: -0.056\n",
      "\n",
      "Epoch 1: returns [0.691] with an input of [1, 0] and a loss of 0.139\n",
      "VALUES AFTER UPDATE: weights: [0.171, -0.428], error: 0.014, bias: -0.043\n",
      "VALUES AFTER UPDATE: weights: [0.658, 0.056], error: 0.022, bias: -0.065\n",
      "VALUES AFTER UPDATE: weights: [0.605, 0.889], error: -0.066, bias: 0.01\n",
      "\n",
      "Epoch 1: returns [0.676] with an input of [0, 0] and a loss of 0.143\n",
      "VALUES AFTER UPDATE: weights: [0.171, -0.428], error: 0.014, bias: -0.057\n",
      "VALUES AFTER UPDATE: weights: [0.658, 0.056], error: 0.023, bias: -0.088\n",
      "VALUES AFTER UPDATE: weights: [0.533, 0.817], error: 0.148, bias: -0.138\n"
     ]
    }
   ],
   "source": [
    "f = Neuron([0.2, -0.4], 0)\n",
    "g = Neuron([0.7, 0.1], 0)\n",
    "\n",
    "layer_1 = NeuronLayer([f, g])\n",
    "\n",
    "o = Neuron([0.6, 0.9], 0)\n",
    "\n",
    "layer_2 = NeuronLayer([o])\n",
    "\n",
    "network = NeuronNetwork([layer_1, layer_2], 1)\n",
    "\n",
    "network.train([[1,1], [0,1], [1,0], [0,0]], [0, 1, 1, 0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je ziet zijn bepaalde waardes net ernaast, ik weet niet 100% waardoor dit komt want de berekeningen kloppen wel. Misschien is het door de round dat ie het net anders afrond in de print. Desondanks kloppen de outputs wel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Half Adder\n",
    "\n",
    "De Half Adder ziet er als volgt uit:\n",
    "<img src=\"./images/ha.png\" alt=\"image\" width=\"400\"/>\n",
    "\n",
    "De values waren als volgt:\n",
    "\n",
    "<img src=\"./images/ha-values.png\" alt=\"image\" width=\"300\"/>\n",
    "\n",
    "Er wordt maar 1 iteratie getoond met een loss. Deze gaan we ook alleen testen omdat de half adder veel print teruggeeft.\n",
    "<img src=\"./images/hu_ff.png\" alt=\"image\" width=\"400\"/>\n",
    "<img src=\"./images/ha_update.png\" alt=\"image\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: returns [0.789, 0.867] with an input of [1, 1] and a loss of 0.334\n",
      "VALUES AFTER UPDATE: weights: [0.0, 0.1], error: -0.0, bias: 0.0\n",
      "VALUES AFTER UPDATE: weights: [0.195, 0.295], error: 0.005, bias: -0.005\n",
      "VALUES AFTER UPDATE: weights: [0.391, 0.491], error: 0.009, bias: -0.009\n",
      "VALUES AFTER UPDATE: weights: [0.531, 0.618, 0.707], error: 0.131, bias: -0.131\n",
      "VALUES AFTER UPDATE: weights: [0.908, 1.01, 1.111], error: -0.015, bias: 0.015\n"
     ]
    }
   ],
   "source": [
    "f = Neuron([0, 0.1], 0)\n",
    "g = Neuron([0.2, 0.3], 0)\n",
    "h = Neuron([0.4, 0.5], 0)\n",
    "# carry\n",
    "c = Neuron([0.9, 1.0, 1.1], 0)\n",
    "# sum\n",
    "s = Neuron([0.6, 0.7, 0.8], 0)\n",
    "\n",
    "layer_1 = NeuronLayer([f, g, h])\n",
    "layer_2 = NeuronLayer([s, c])\n",
    "\n",
    "network = NeuronNetwork([layer_1, layer_2], 1)\n",
    "\n",
    "network.train([[1, 1]], [[0, 1]], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De dit is interessant. De output weights en biases en errors zijn goed, maar de loss is anders. De geupdate weights van g en h zijn ook goed, maar die van f zijn weer anders. En bij zowel f,g en h zijn de biases fout, maar ondanks dat die fout zijn is de output dus wel helemaal correct. Misschien is de bias anders door de learning rate. Deze is namelijk niet aangegeven bij het begin dus ging ik ervan uit dat het 1 was aangezien het ook zo was bij de XOR en AND gate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "\n",
    "Aangezien ik redelijk wat moet inleveren, waaronder nog P5 heb ik besloten de dataset tests niet uit te voeren."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

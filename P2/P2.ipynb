{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2\n",
    "Voor P2 maken we gebruik van de perceptronnetwork van P1 en de geupdate perceptron. We gebruiken een willikeurige learning rule. We importeren ook de iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from P2.code.perceptron import Perceptron\n",
    "from P2.code.perceptronlayer import PerceptronLayer\n",
    "from P2.code.perceptronnetwork import PerceptronNetwork\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AND Test\n",
    "We gaan eerst de AND port testen. We geven de Perceptron willekeurige waardes en gaan kijken hoelang het duurt voordat de Perceptron op het goeie antwoord komt met behulp van de learning rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# random perceptron\n",
    "p1 = Perceptron([20, 38], 11.5, 0.8)\n",
    "print(p1.output([0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het bovenste voorbeeld had 0 moeten zijn maar is een 1. We maken nu een functie voor de learning rule en passen dit toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    The loop given below is a loop that makes it possible to run any random perceptron \n",
    "    through the learning rule and compeletly fix it (at least it is suppose to). It keeps looping through all possible inputs\n",
    "    and is keeping track of a score. If the score is the same amount as the maximum inputs (in this case 4) it stops.\n",
    "    The loop needs to change based on the amount of inputs and the target that you want.\n",
    "    \n",
    "    An AND port has the targets [0,0,0,1] so the loop below is based on that. But a XOR port has the targets [0,1,1,0].\n",
    "    if that is the case you need to change the target values of the port. Keep this in mind if you want to test different things\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def AND_lr():\n",
    "    while p1.score != 4:\n",
    "        p1.score = 0\n",
    "        for x in range(0,2):\n",
    "            for y in range(0,2):\n",
    "                if [x,y] == [0,0]:\n",
    "                    p1.update([x,y], 0)\n",
    "                elif [x,y] == [0,1]:\n",
    "                    p1.update([x,y], 0)\n",
    "                elif [x,y] == [1,0]:\n",
    "                    p1.update([x,y], 0)\n",
    "                elif [x,y] == [1,1]:\n",
    "                    p1.update([x,y], 1)\n",
    "AND_lr()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu tonen we het resultaat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "Weight: [10.399999999999991, 19.60000000000001] \n",
      "Bias: -20.50000000000001 \n",
      "Error: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(p1.output([0,0]))\n",
    "print(p1.output([0,1]))\n",
    "print(p1.output([1,0]))\n",
    "print(p1.output([1,1]))\n",
    "\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR Test\n",
    "We doen nu dezelfde test als met de AND port, alleen nu met de XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = Perceptron([0.1, 0.5], 0.8, 0.3)\n",
    "p2.output([0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het bovenste voorbeeld had moeten eindigen met een 0, maar is dus 1. Echter Is het een XOR niet linear scheidbaar en kan het niet opgelost worden met maar 1 perceptron. Hieronder laten we zien dat je makkelijk 1 perceptron kan leren om 1 specifieke output te krijgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Weight: [0.1, 0.5] \n",
      "Bias: -0.09999999999999998 \n",
      "Error: 1.0\n"
     ]
    }
   ],
   "source": [
    "while p2.output([0,0]) != 0:\n",
    "    p2.update([0,0], 0)\n",
    "\n",
    "    \n",
    "print(p2.output([0,0]))\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Weight: [0.1, 0.5] \n",
      "Bias: -0.09999999999999998 \n",
      "Error: 1.0\n"
     ]
    }
   ],
   "source": [
    "while p2.output([0,1]) != 1:\n",
    "    p2.update([0,1], 1)\n",
    "\n",
    "    \n",
    "print(p2.output([0,1]))\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alleen als je probeert een perceptron te maken die bij alle 4 de inputs een correct antwoord kan geven zul je zien dat dat nooit kan. De loop hieronder zal dus ook nooit stoppen tenzij je er een grens bij zet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: [-0.19999999999999998, 0.2] \n",
      "Bias: -0.39999999999999997 \n",
      "Error: 1.0\n",
      "Weight: [-0.19999999999999998, 0.2] \n",
      "Bias: -0.09999999999999998 \n",
      "Error: 1.0\n",
      "Weight: [-0.19999999999999998, -0.09999999999999998] \n",
      "Bias: -0.09999999999999998 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: -0.09999999999999998 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n",
      "Weight: [-0.5, -0.09999999999999998] \n",
      "Bias: 0.2 \n",
      "Error: 1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Same loop as the AND port. except different targets (as said before)\n",
    "\"\"\"\n",
    "def XOR_lr():\n",
    "    n = 0\n",
    "    while p2.score != 4:\n",
    "        if n == 100:\n",
    "            break\n",
    "            \n",
    "        p2.score = 0\n",
    "        for x in range(0,2):\n",
    "            for y in range(0,2):\n",
    "                if [x,y] == [0,0]:\n",
    "                    p2.update([x,y], 0)\n",
    "                elif [x,y] == [0,1]:\n",
    "                    p2.update([x,y], 1)\n",
    "                elif [x,y] == [1,0]:\n",
    "                    p2.update([x,y], 1)\n",
    "                elif [x,y] == [1,1]:\n",
    "                    p2.update([x,y], 0)\n",
    "        n += 1\n",
    "        print(p2)\n",
    "        \n",
    "        \n",
    "XOR_lr()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je ziet komt er gewoon een punt dat er niks meer veranderd, maar ook de perceptron nog niet goed getrained is. Hieronder printen we het eindresultaat na 100 pogingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(p2.output([0,0]))\n",
    "print(p2.output([0,1]))\n",
    "print(p2.output([1,0]))\n",
    "print(p2.output([1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IRIS Dataset\n",
    "We gaan nu proberen de learning rule toe te passen op de iris dataset. Hier gebruiken we een random seed voor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\brand\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1760236)\n",
    "iris = load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maken nu een perceptron met 4 random weights, een random bias en een random learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = Perceptron([random.randint(0,9),random.randint(0,9),random.randint(0,9),random.randint(0,9)], random.randint(0,9), random.randint(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu pakken we de juiste data uit de iris dataset en gebruiken passen we de learning rule op de perceptron toe. We testen eerst de eerste 2 klasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris['data']\n",
    "\n",
    "# get first two classes (targets 0 - 100)\n",
    "t1 = iris.target[:100]\n",
    "correct = 0\n",
    "for x in range(0, len(t1)):\n",
    "    for y in range(0,10):\n",
    "        p3.update(data[x], t1[x])\n",
    "    \n",
    "    if p3.output([data[x]]) == t1[x]:\n",
    "        correct += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder een kleine score die ik bereken door te kijken hoeveel er goed is na 10 pogingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = correct / len(t1)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je ziet hebben we een score van 1.0 dus heeft onze learning rule alles goed kunnen classificeren. Nu gaan we het testen met alle 3 de klasses. We maken hiervoor weer een nieuwe perceptron zodat deze niet aangepast is door de resultaten van de vorige test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = Perceptron([random.randint(0,9),random.randint(0,9),random.randint(0,9),random.randint(0,9)], random.randint(0,9), random.randint(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = iris['target']\n",
    "correct = 0\n",
    "for x in range(0,len(data)):\n",
    "    for y in range(0, 10):\n",
    "        p4.update(data[x], t2[x])\n",
    "        \n",
    "    if p4.output([data[x]]) == t2[x]:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder kijken we weer naar de score na 10 pogingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = correct / len(t2)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
